{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Train an XGBoost model to predict scan parquet GPU scan time."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38b70794d584d102"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "cpu_profile_dirs = [\"/opt/data/profiles/dataproc-cpu-sf100\",\n",
    "                    \"/opt/data/profiles/dataproc-cpu-sf3k\",\n",
    "                    \"/opt/data/profiles/dataproc-cpu-sf5k\",\n",
    "                    \"/opt/data/profiles/dataproc-cpu-sf10k\"]\n",
    "gpu_profile_dirs = [\"/opt/data/profiles/dataproc-gpu-sf100\",\n",
    "                    \"/opt/data/profiles/dataproc-gpu-sf3k\",\n",
    "                    \"/opt/data/profiles/dataproc-gpu-sf5k\",\n",
    "                    \"/opt/data/profiles/dataproc-gpu-sf10k\"]\n",
    "cpu_event_dirs = [\"/opt/data/events/dataproc-cpu-sf100\",\n",
    "                  \"/opt/data/events/dataproc-cpu-sf3k\",\n",
    "                  \"/opt/data/events/dataproc-cpu-sf5k\",\n",
    "                  \"/opt/data/events/dataproc-cpu-sf10k\"]\n",
    "gpu_event_dirs = [\"/opt/data/events/dataproc-gpu-sf100\",\n",
    "                  \"/opt/data/events/dataproc-gpu-sf3k\",\n",
    "                  \"/opt/data/events/dataproc-gpu-sf5k\",\n",
    "                  \"/opt/data/events/dataproc-gpu-sf10k\"]\n",
    "scale_factors = [\"100\", \"3K\", \"5K\", \"10K\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bfab33d0f98d9ce"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class ScanParquet:\n",
    "    def __init__(self, group=None):\n",
    "        self.num_output_rows = 0\n",
    "        self.num_files_read = 0\n",
    "        self.metadata_time = 0\n",
    "        self.size_files_read = 0\n",
    "        self.scan_time_median = 0\n",
    "        self.scan_time_max = 0\n",
    "        self.scan_time_total = 0\n",
    "        self.num_partitions_read = 0\n",
    "        self.dynamic_partition_pruning_time = 0\n",
    "        self.static_num_files_read = 0\n",
    "        self.static_size_files_read = 0\n",
    "        self.accumulator_id = 0\n",
    "        if group is None:\n",
    "            return\n",
    "        for row in group.itertuples():\n",
    "            if row.name == \"number of output rows\" or row.name == \"output rows\":\n",
    "                self.num_output_rows = row.total\n",
    "            elif row.name == \"number of files read\":\n",
    "                self.num_files_read = row.total\n",
    "            elif row.name == \"metadata time\":\n",
    "                self.metadata_time = row.total\n",
    "            elif row.name == \"size of files read\":\n",
    "                self.size_files_read = row.total\n",
    "            elif row.name == \"scan time\":\n",
    "                self.scan_time_median = row.median\n",
    "                self.scan_time_max = row.max\n",
    "                self.scan_time_total = row.total\n",
    "                self.accumulator_id = row.accumulatorId\n",
    "            elif row.name == \"number of partitions read\" or row.name == \"partitions\":\n",
    "                self.num_partitions_read = row.total\n",
    "            elif row.name == \"dynamic partition pruning time\":\n",
    "                self.dynamic_partition_pruning_time = row.total\n",
    "            elif row.name == \"static number of files read\":\n",
    "                self.static_num_files_read = row.total\n",
    "            elif row.name == \"static size of files read\":\n",
    "                self.static_size_files_read = row.total\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, ScanParquet):\n",
    "            return (self.num_output_rows == 0 or\n",
    "                    other.num_output_rows == 0 or\n",
    "                    self.num_output_rows == other.num_output_rows) and \\\n",
    "                (self.num_files_read == 0 or\n",
    "                 other.num_files_read == 0 or\n",
    "                 self.num_files_read == other.num_files_read) and \\\n",
    "                (self.size_files_read == 0 or\n",
    "                 other.size_files_read == 0 or\n",
    "                 self.size_files_read == other.size_files_read) and \\\n",
    "                (self.num_partitions_read == 0 or\n",
    "                 other.num_partitions_read == 0 or\n",
    "                 self.num_partitions_read == other.num_partitions_read)\n",
    "        return False\n",
    "\n",
    "    def __str__(self):\n",
    "        return (f\"{self.num_output_rows}, {self.num_files_read}, {self.size_files_read}, {self.num_partitions_read}, \"\n",
    "                f\"{self.scan_time_total}\")\n",
    "\n",
    "\n",
    "def collect(node, scan_list, scan_map):\n",
    "    if node['nodeName'] == 'Scan parquet ' or node['nodeName'] == 'GpuScan parquet ':\n",
    "        for m in node['metrics']:\n",
    "            if m['name'] == 'scan time':\n",
    "                accumulator_id = m['accumulatorId']\n",
    "                scan_list.append(scan_map.get(accumulator_id, ScanParquet()))\n",
    "    for child in node['children']:\n",
    "        collect(child, scan_list, scan_map)\n",
    "\n",
    "\n",
    "def collect_scans(profile_dir, event_file):\n",
    "    sql_info = pd.read_csv(f\"{profile_dir}/sql_plan_metrics_for_application.csv\")\n",
    "    condition = (sql_info['nodeName'] == 'Scan parquet ') | (sql_info['nodeName'] == 'GpuScan parquet ')\n",
    "    filtered = sql_info[condition]\n",
    "    grouped = filtered.groupby(\"nodeID\")\n",
    "    scan_dict = {}\n",
    "    for _, group in grouped:\n",
    "        scan = ScanParquet(group)\n",
    "        scan_dict[scan.accumulator_id] = scan\n",
    "\n",
    "    scans = []\n",
    "    with open(event_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            event = json.loads(line)\n",
    "            if \"sparkPlanInfo\" in event:\n",
    "                scans.clear()\n",
    "                collect(event[\"sparkPlanInfo\"], scans, scan_dict)\n",
    "    return sorted(scans, key=lambda s: (s.num_output_rows, s.num_files_read, s.size_files_read, s.num_partitions_read))\n",
    "\n",
    "\n",
    "num_scale_factors = len(scale_factors)\n",
    "cpu_times = []\n",
    "gpu_times = []\n",
    "for i in range(num_scale_factors):\n",
    "    cpu_profiles = os.listdir(cpu_profile_dirs[i])\n",
    "    cpu_profiles.sort()\n",
    "    num_apps = len(cpu_profiles)\n",
    "    gpu_profiles = os.listdir(gpu_profile_dirs[i])\n",
    "    gpu_profiles.sort()\n",
    "    cpu_events = os.listdir(cpu_event_dirs[i])\n",
    "    cpu_events.sort()\n",
    "    gpu_events = os.listdir(gpu_event_dirs[i])\n",
    "    gpu_events.sort()\n",
    "    assert num_apps == len(gpu_profiles) == len(cpu_events) == len(gpu_events)\n",
    "    for j in range(num_apps):\n",
    "        print(f\"Processing cpu profile {cpu_profiles[j]}, event file {cpu_events[j]}\")\n",
    "        cpu_scans = collect_scans(f\"{cpu_profile_dirs[i]}/{cpu_profiles[j]}\",\n",
    "                                  f\"{cpu_event_dirs[i]}/{cpu_events[j]}\")\n",
    "        print(f\"Processing gpu profile {gpu_profiles[j]}, event file {gpu_events[j]}\")\n",
    "        gpu_scans = collect_scans(f\"{gpu_profile_dirs[i]}/{gpu_profiles[j]}\",\n",
    "                                  f\"{gpu_event_dirs[i]}/{gpu_events[j]}\")\n",
    "        if cpu_scans != gpu_scans:\n",
    "            print(\"Warning: cpu and gpu scans are different:\")\n",
    "            print(\"; \".join(str(s) for s in cpu_scans))\n",
    "            print(\"; \".join(str(s) for s in gpu_scans))\n",
    "            continue\n",
    "        cpu_times.extend(cpu_scans)\n",
    "        gpu_times.extend(gpu_scans)\n",
    "print(f\"Total number of cpu scans: {len(cpu_times)}\")\n",
    "print(f\"Total number of gpu scans: {len(gpu_times)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75275cfe783dd3d0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "header = [\"gpu_scan_time_total\", \"num_output_rows\", \"num_files_read\", \"metadata_time\", \"size_files_read\",\n",
    "          \"scan_time_median\", \"scan_time_max\", \"scan_time_total\", \"num_partitions_read\",\n",
    "          \"dynamic_partition_pruning_time\", \"static_num_files_read\", \"static_size_files_read\"]\n",
    "fields = header[1:]\n",
    "\n",
    "with open(\"scan_parquet.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=header)\n",
    "    writer.writeheader()\n",
    "    assert len(cpu_times) == len(gpu_times)\n",
    "    for i, cpu_time in enumerate(cpu_times):\n",
    "        row = {field: getattr(cpu_time, field) for field in fields}\n",
    "        row[\"gpu_scan_time_total\"] = gpu_times[i].scan_time_total\n",
    "        writer.writerow(row)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3971fa3b4a1d0c11",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.read_csv('scan_parquet.csv', na_values=[\"0\"])\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(df.shape[0])\n",
    "X = df.iloc[:, :1]\n",
    "y = df.iloc[:, 0]\n",
    "dtrain = xgb.DMatrix(X, label=y, missing=np.nan)\n",
    "param = {\n",
    "    'validate_parameters': True,\n",
    "    'eta': 0.1,\n",
    "    'max_depth': 0,\n",
    "    'tree_method': 'hist',\n",
    "    'grow_policy': 'lossguide',\n",
    "    'max_leaves': 255,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "}\n",
    "num_round = 500\n",
    "results = xgb.cv(\n",
    "    params=param,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=num_round,\n",
    "    nfold=10,\n",
    "    seed=42,\n",
    "    callbacks=[\n",
    "        xgb.callback.EvaluationMonitor(show_stdv=False),\n",
    "        xgb.callback.EarlyStopping(3),\n",
    "    ],\n",
    ")\n",
    "print(results)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8755e00787bc8c1",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
