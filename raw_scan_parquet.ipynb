{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Parse the raw event log to compare CPU and GPU scan parquet operations."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38b70794d584d102"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "\n",
    "# SF100\n",
    "# cpu_profiles = \"/opt/data/profiles/dataproc-cpu-sf100\"\n",
    "# gpu_profiles = \"/opt/data/profiles/dataproc-gpu-sf100\"\n",
    "# cpu_events = \"/opt/data/events/dataproc-cpu-sf100\"\n",
    "# gpu_events = \"/opt/data/events/dataproc-gpu-sf100\"\n",
    "\n",
    "# SF3K\n",
    "# cpu_profiles = \"/opt/data/profiles/dataproc-cpu-sf3k\"\n",
    "# gpu_profiles = \"/opt/data/profiles/dataproc-gpu-sf3k\"\n",
    "# cpu_events = \"/opt/data/events/dataproc-cpu-sf3k\"\n",
    "# gpu_events = \"/opt/data/events/dataproc-gpu-sf3k\"\n",
    "\n",
    "# SF5K\n",
    "# cpu_profiles = \"/opt/data/profiles/dataproc-cpu-sf5k\"\n",
    "# gpu_profiles = \"/opt/data/profiles/dataproc-gpu-sf5k\"\n",
    "# cpu_events = \"/opt/data/events/dataproc-cpu-sf5k\"\n",
    "# gpu_events = \"/opt/data/events/dataproc-gpu-sf5k\"\n",
    "\n",
    "# SF10K\n",
    "cpu_profiles = \"/opt/data/profiles/dataproc-cpu-sf10k\"\n",
    "gpu_profiles = \"/opt/data/profiles/dataproc-gpu-sf10k\"\n",
    "cpu_events = \"/opt/data/events/dataproc-cpu-sf10k\"\n",
    "gpu_events = \"/opt/data/events/dataproc-gpu-sf10k\"\n",
    "\n",
    "cpu_profile_dirs = os.listdir(cpu_profiles)\n",
    "cpu_profile_dirs.sort()\n",
    "gpu_profile_dirs = os.listdir(gpu_profiles)\n",
    "gpu_profile_dirs.sort()\n",
    "\n",
    "cpu_event_files = os.listdir(cpu_events)\n",
    "cpu_event_files.sort()\n",
    "gpu_event_files = os.listdir(gpu_events)\n",
    "gpu_event_files.sort()\n",
    "\n",
    "num_apps = len(cpu_event_files)\n",
    "assert len(cpu_event_files) == num_apps\n",
    "assert len(gpu_event_files) == num_apps\n",
    "assert len(cpu_profile_dirs) == num_apps\n",
    "assert len(gpu_profile_dirs) == num_apps\n",
    "num_apps"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bfab33d0f98d9ce"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class ScanParquet:\n",
    "    def __init__(self, group=None):\n",
    "        self.output_rows = 0\n",
    "        self.files_read = 0\n",
    "        self.size_files_read = 0\n",
    "        self.partitions_read = 0\n",
    "        self.scan_time = 0\n",
    "        if group is None:\n",
    "            return\n",
    "        for row in group.itertuples():\n",
    "            if row.name == \"number of output rows\" or row.name == \"output rows\":\n",
    "                self.output_rows = row.total\n",
    "            elif row.name == \"number of files read\":\n",
    "                self.files_read = row.total\n",
    "            elif row.name == \"size of files read\":\n",
    "                self.size_files_read = row.total\n",
    "            elif row.name == \"number of partitions read\" or row.name == \"partitions\":\n",
    "                self.partitions_read = row.total\n",
    "            elif row.name == \"scan time\":\n",
    "                self.scan_time = row.total\n",
    "                self.accumulator_id = row.accumulatorId\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, ScanParquet):\n",
    "            return (self.output_rows == 0 or other.output_rows == 0 or self.output_rows == other.output_rows) and \\\n",
    "                (self.files_read == 0 or other.files_read == 0 or self.files_read == other.files_read) and \\\n",
    "                (\n",
    "                        self.size_files_read == 0 or other.size_files_read == 0 or self.size_files_read == other.size_files_read) and \\\n",
    "                (\n",
    "                        self.partitions_read == 0 or other.partitions_read == 0 or self.partitions_read == other.partitions_read)\n",
    "        return False\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.output_rows}, {self.files_read}, {self.size_files_read}, {self.partitions_read}, {self.scan_time}\"\n",
    "\n",
    "\n",
    "def collect(node, scan_list, scan_map):\n",
    "    if node['nodeName'] == 'GpuScan parquet ' or node['nodeName'] == 'Scan parquet ':\n",
    "        for m in node['metrics']:\n",
    "            if m['name'] == 'scan time':\n",
    "                accumulator_id = m['accumulatorId']\n",
    "                scan_list.append(scan_map.get(accumulator_id, ScanParquet()))\n",
    "    for child in node['children']:\n",
    "        collect(child, scan_list, scan_map)\n",
    "\n",
    "\n",
    "def collect_scans(profile_dir, event_file):\n",
    "    sql_info = pd.read_csv(f\"{profile_dir}/sql_plan_metrics_for_application.csv\")\n",
    "    filtered = sql_info[(sql_info[\"nodeName\"].str.contains(\"Scan parquet \"))]\n",
    "    grouped = filtered.groupby(\"nodeID\")\n",
    "    scan_dict = {}\n",
    "    for _, group in grouped:\n",
    "        scan = ScanParquet(group)\n",
    "        scan_dict[scan.accumulator_id] = scan\n",
    "\n",
    "    scans = []\n",
    "    with open(event_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            event = json.loads(line)\n",
    "            if \"sparkPlanInfo\" in event:\n",
    "                scans.clear()\n",
    "                collect(event[\"sparkPlanInfo\"], scans, scan_dict)\n",
    "    return sorted(scans, key=lambda s: (s.output_rows, s.files_read, s.size_files_read, s.partitions_read))\n",
    "\n",
    "\n",
    "cpu_times = []\n",
    "gpu_times = []\n",
    "cpu_query_times = []\n",
    "gpu_query_times = []\n",
    "for i in range(num_apps):\n",
    "    print(f\"Processing cpu profile {cpu_profile_dirs[i]}, event file {cpu_event_files[i]}\")\n",
    "    cpu_scans = collect_scans(f\"{cpu_profiles}/{cpu_profile_dirs[i]}\", f\"{cpu_events}/{cpu_event_files[i]}\")\n",
    "    print(f\"Processing gpu profile {gpu_profile_dirs[i]}, event file {gpu_event_files[i]}\")\n",
    "    gpu_scans = collect_scans(f\"{gpu_profiles}/{gpu_profile_dirs[i]}\", f\"{gpu_events}/{gpu_event_files[i]}\")\n",
    "    if cpu_scans != gpu_scans:\n",
    "        print(\"Warning: cpu and gpu scan times are different:\")\n",
    "        print(\"; \".join(str(s) for s in cpu_scans))\n",
    "        print(\"; \".join(str(s) for s in gpu_scans))\n",
    "        continue\n",
    "    cpu_times.extend(s.scan_time for s in cpu_scans)\n",
    "    gpu_times.extend(s.scan_time for s in gpu_scans)\n",
    "    cpu_query_times.append(sum(s.scan_time for s in cpu_scans))\n",
    "    gpu_query_times.append(sum(s.scan_time for s in gpu_scans))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75275cfe783dd3d0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create a scatter plot\n",
    "plt.scatter(cpu_times, gpu_times)\n",
    "\n",
    "# Calculate the linear regression line\n",
    "# slope, intercept = np.polyfit(cpu_times, gpu_times, 1)\n",
    "X = np.array(cpu_times).reshape(-1, 1)\n",
    "y = np.array(gpu_times)\n",
    "regressor = HuberRegressor()\n",
    "regressor.fit(X, y)\n",
    "slope = regressor.coef_[0]\n",
    "intercept = regressor.intercept_\n",
    "print(slope, intercept)\n",
    "regression_line = np.array(cpu_times) * slope + intercept\n",
    "\n",
    "# Plot the linear regression line\n",
    "plt.plot(cpu_times, regression_line, color='red')  # you can choose any color you like for the line\n",
    "\n",
    "# Adding title and labels (optional)\n",
    "plt.title(\"Scan Times\")\n",
    "plt.xlabel(\"CPU\")\n",
    "plt.ylabel(\"GPU\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2bc8bca893683344",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create a scatter plot\n",
    "plt.scatter(cpu_query_times, gpu_query_times)\n",
    "print(len(cpu_query_times), len(gpu_query_times))\n",
    "\n",
    "# Calculate the linear regression line\n",
    "slope, intercept = np.polyfit(cpu_query_times, gpu_query_times, 1)\n",
    "print(slope, intercept)\n",
    "regression_line = np.array(cpu_query_times) * slope + intercept\n",
    "\n",
    "# Plot the linear regression line\n",
    "plt.plot(cpu_query_times, regression_line, color='red')  # you can choose any color you like for the line\n",
    "\n",
    "# Adding title and labels (optional)\n",
    "plt.title(\"Total Scan Times Per Query\")\n",
    "plt.xlabel(\"CPU\")\n",
    "plt.ylabel(\"GPU\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5d6e30fb6fbf9ee",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e890ababcc4be06c",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
