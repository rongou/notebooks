{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Parse the profiler output to match up stages between CPU and GPU queries."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38b70794d584d102"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import heapq\n",
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "cpu_profile_dirs = [\"/opt/data/profiles/dataproc-cpu-sf100\",\n",
    "                    \"/opt/data/profiles/dataproc-cpu-sf3k\",\n",
    "                    \"/opt/data/profiles/dataproc-cpu-sf5k\",\n",
    "                    \"/opt/data/profiles/dataproc-cpu-sf10k\"]\n",
    "gpu_profile_dirs = [\"/opt/data/profiles/dataproc-gpu-sf100\",\n",
    "                    \"/opt/data/profiles/dataproc-gpu-sf3k\",\n",
    "                    \"/opt/data/profiles/dataproc-gpu-sf5k\",\n",
    "                    \"/opt/data/profiles/dataproc-gpu-sf10k\"]\n",
    "scale_factors = [\"100\", \"3K\", \"5K\", \"10K\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bfab33d0f98d9ce"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Stage:\n",
    "    def __init__(self, row, whole_stage_codegen_map):\n",
    "        self.sql_id = row.sqlID\n",
    "        self.job_id = row.jobID\n",
    "        self.stage_id = row.stageId\n",
    "        stage_attempt_id = row.stageAttemptId\n",
    "        assert stage_attempt_id == 0\n",
    "        self.stage_duration = row[\"Stage Duration\"]\n",
    "        self.sql_nodes = str(row[\"SQL Nodes(IDs)\"])\n",
    "\n",
    "        nodes = self.sql_nodes.split(\",\")\n",
    "        cleaned_nodes = [re.sub(r'\\(\\d+\\)$', '', s).strip() for s in nodes]\n",
    "        if whole_stage_codegen_map is None:\n",
    "            expanded_nodes = cleaned_nodes\n",
    "        else:\n",
    "            expanded_nodes = []\n",
    "            for n in cleaned_nodes:\n",
    "                if n in whole_stage_codegen_map:\n",
    "                    expanded_nodes.extend(whole_stage_codegen_map[n])\n",
    "                else:\n",
    "                    expanded_nodes.append(n)\n",
    "        filtered_nodes = [n for n in expanded_nodes if\n",
    "                          n != \"ColumnarToRow\" and\n",
    "                          n != \"GpuShuffleCoalesce\" and\n",
    "                          n != \"GpuCoalesceBatches\" and\n",
    "                          n != \"GpuColumnarToRow\" and\n",
    "                          n != \"GpuRowToColumnar\"]\n",
    "        de_gpu_nodes = [n\n",
    "                        .replace(\"GpuShuffledHashJoin\", \"SortMergeJoin\")\n",
    "                        .replace(\"GpuColumnar\", \"\")\n",
    "                        .replace(\"Gpu\", \"\")\n",
    "                        for n in filtered_nodes]\n",
    "        self.canonical_sql_nodes = de_gpu_nodes\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.sql_id}, {self.job_id}, {self.stage_id}, {self.stage_duration}, {self.canonical_sql_nodes}\"\n",
    "\n",
    "\n",
    "class CombinedStage:\n",
    "    def __init__(self, stages):\n",
    "        self.stages = stages\n",
    "        self.stage_duration = sum([s.stage_duration for s in stages])\n",
    "        self.canonical_sql_nodes = [n for s in stages for n in s.canonical_sql_nodes]\n",
    "        if len(stages) > 1:\n",
    "            nodes = self.canonical_sql_nodes\n",
    "            self.canonical_sql_nodes = [nodes[0]]\n",
    "            for node_index in range(1, len(nodes)):\n",
    "                n = nodes[node_index]\n",
    "                if n != \"Exchange\" or n != nodes[node_index - 1]:\n",
    "                    self.canonical_sql_nodes.append(nodes[node_index])\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.stage_duration}, {self.canonical_sql_nodes}\"\n",
    "\n",
    "\n",
    "def build_whole_stage_codegen_map(profile):\n",
    "    df = pd.read_csv(f\"{profile}/wholestagecodegen_mapping.csv\")\n",
    "    filtered = df[df['Child Node'] != \"ColumnarToRow\"]\n",
    "    sql_to_child_nodes = filtered.groupby('SQL Node')['Child Node'].apply(list).to_dict()\n",
    "    return sql_to_child_nodes\n",
    "\n",
    "\n",
    "def collect_stages(profile, whole_stage_codegen_map=None):\n",
    "    df = pd.read_csv(f\"{profile}/sql_to_stage_information.csv\")\n",
    "    stages = []\n",
    "    for _, row in df.iterrows():\n",
    "        stages.append(Stage(row, whole_stage_codegen_map))\n",
    "    return stages\n",
    "\n",
    "\n",
    "def combine_stages(stages):\n",
    "    combined = []\n",
    "    # Add single stages first.\n",
    "    for s in stages:\n",
    "        combined.append(CombinedStage([s]))\n",
    "    # Add combined stages.\n",
    "    for s in stages:\n",
    "        if s.canonical_sql_nodes[-1] != \"Scan parquet\":\n",
    "            for t in stages:\n",
    "                combined.append(CombinedStage([s, t]))\n",
    "    return combined\n",
    "\n",
    "\n",
    "def calculate_match_score(cpu_stage, gpu_stage):\n",
    "    total_length = len(cpu_stage.canonical_sql_nodes) + len(gpu_stage.canonical_sql_nodes)\n",
    "    x = list(reversed(cpu_stage.canonical_sql_nodes))\n",
    "    y = list(reversed(gpu_stage.canonical_sql_nodes))\n",
    "    matches = 0\n",
    "    i, j = 0, 0\n",
    "    while i < len(x) and j < len(y):\n",
    "        found_match = False\n",
    "\n",
    "        # Find the earliest match from current indices onwards\n",
    "        for offset in range(max(len(x) - i, len(y) - j)):\n",
    "            if i + offset < len(x) and x[i + offset] in y[j:]:\n",
    "                j_match = y[j:].index(x[i + offset]) + j\n",
    "                matches += 1\n",
    "                i += offset + 1\n",
    "                j = j_match + 1\n",
    "                found_match = True\n",
    "                break  # Break after finding the first match\n",
    "\n",
    "            if j + offset < len(y) and y[j + offset] in x[i:]:\n",
    "                i_match = x[i:].index(y[j + offset]) + i\n",
    "                matches += 1\n",
    "                j += offset + 1\n",
    "                i = i_match + 1\n",
    "                found_match = True\n",
    "                break  # Break after finding the first match\n",
    "\n",
    "        if not found_match:  # No match found in this iteration, break the loop\n",
    "            break\n",
    "    return matches * 2 / total_length\n",
    "\n",
    "\n",
    "def match_stages(cpu_list, gpu_list):\n",
    "    matches = []\n",
    "    for cpu in cpu_list:\n",
    "        heap = []\n",
    "        for gpu_index, gpu in enumerate(gpu_list):\n",
    "            score = calculate_match_score(cpu, gpu)\n",
    "            heapq.heappush(heap, (-score, gpu_index))\n",
    "        largest_index = heapq.heappop(heap)[1]\n",
    "        largest_gpu = gpu_list.pop(largest_index)\n",
    "        matches.append((cpu, largest_gpu))\n",
    "    return matches\n",
    "\n",
    "\n",
    "num_scale_factors = len(scale_factors)\n",
    "# num_scale_factors = 1\n",
    "num_cpu_stages = 0\n",
    "num_gpu_stages = 0\n",
    "cpu_stage_times = [[] for _ in range(num_scale_factors)]\n",
    "gpu_stage_times = [[] for _ in range(num_scale_factors)]\n",
    "\n",
    "for scale_factor in range(num_scale_factors):\n",
    "    cpu_apps = os.listdir(cpu_profile_dirs[scale_factor])\n",
    "    cpu_apps.sort()\n",
    "    gpu_apps = os.listdir(gpu_profile_dirs[scale_factor])\n",
    "    gpu_apps.sort()\n",
    "    assert len(cpu_apps) == len(gpu_apps)\n",
    "    for app in range(len(cpu_apps)):\n",
    "    # for app in range(1):\n",
    "        print(\n",
    "            f\"Processing cpu profile {cpu_apps[app]}, gpu profile {gpu_apps[app]}, scale factor {scale_factors[scale_factor]}...\")\n",
    "        whole_stage_codegen_dict = build_whole_stage_codegen_map(f\"{cpu_profile_dirs[scale_factor]}/{cpu_apps[app]}\")\n",
    "        cpu_stages = collect_stages(f\"{cpu_profile_dirs[scale_factor]}/{cpu_apps[app]}\", whole_stage_codegen_dict)\n",
    "        gpu_stages = collect_stages(f\"{gpu_profile_dirs[scale_factor]}/{gpu_apps[app]}\")\n",
    "        combined_stages = combine_stages(gpu_stages)\n",
    "        # print(\"CPU stages:\")\n",
    "        # for stage in cpu_stages:\n",
    "        #     print(stage.canonical_sql_nodes)\n",
    "        # print(\"GPU stages:\")\n",
    "        # for stage in gpu_stages:\n",
    "        #     print(stage.canonical_sql_nodes)\n",
    "        # print(\"Combined GPU stages:\")\n",
    "        # for stage in combined_stages:\n",
    "        #     print(stage.canonical_sql_nodes)\n",
    "        num_cpu_stages += len(cpu_stages)\n",
    "        num_gpu_stages += len(gpu_stages)\n",
    "        matched = match_stages(cpu_stages, combined_stages)\n",
    "        # print(f\"Found matches: {len(matched)}\")\n",
    "        for c, g in matched:\n",
    "            # print(f\"CPU: {cpu.canonical_sql_nodes}\\nGPU: {gpu.canonical_sql_nodes}\\n\")\n",
    "            cpu_stage_times[scale_factor].append(c.stage_duration)\n",
    "            gpu_stage_times[scale_factor].append(g.stage_duration)\n",
    "print(f\"Found {num_cpu_stages} CPU stages and {num_gpu_stages} GPU stages\")\n",
    "print(f\"Matched {sum(len(times) for times in cpu_stage_times)} CPU stages and {sum(len(times) for times in gpu_stage_times)} GPU stages\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75275cfe783dd3d0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for sf in range(num_scale_factors):\n",
    "    plt.scatter(cpu_stage_times[sf], gpu_stage_times[sf])\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.title(f\"CPU vs GPU Stage Times - SF{scale_factors[sf]}\")\n",
    "    plt.xlabel(\"CPU Stage Time\")\n",
    "    plt.ylabel(\"GPU Stage Time\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68dc0fe4e4ff1059",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for sf in range(num_scale_factors):\n",
    "    plt.scatter(cpu_stage_times[sf], gpu_stage_times[sf], label=f\"SF{scale_factors[sf]}\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.title(f\"CPU vs GPU Stage Times - SF{scale_factors[sf]}\")\n",
    "plt.xlabel(\"CPU Stage Time\")\n",
    "plt.ylabel(\"GPU Stage Time\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "857294d488d10a50",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
